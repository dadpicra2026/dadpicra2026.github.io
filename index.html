<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content=".">
  <meta name="keywords" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Delay-Aware Diffusion Policy: Bridging the Observation–Execution Gap in Dynamic Tasks</title>

  <link href="https://fonts.googleapis.com/css2?family=DM+Mono&family=DM+Sans:wght@400;500;700&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
</head>
<body>

<section class="hero masthead-hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered masthead">
          <h1 class="title is-1 headline">Delay-Aware Diffusion Policy: Bridging the Observation–Execution Gap in Dynamic Tasks</h1>
          <div class="is-size-5 byline">
            <span class="byline-item">
              Annonymous Authors  
            </span>                            
          </div>
          <div class="column has-text-centered">
            <div class="action-bar">
              <!-- Paper (PDF) -->
              <span class="action-item">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper (PDF)</span>
                </a>
              </span>
              <!-- Video -->
              <span class="action-item">
                <a href="#video"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-video"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code -->
              <span class="action-item">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                </a>
              </span>
            </div>
          </div>
          <!-- Two images side by side -->
          <div class="columns is-mobile is-centered" style="margin-top: 0.75rem;">
            <div class="column is-half has-text-centered">
              <figure>
                <img src="./static/images/pingpong_dp.png"
                     style="border-radius: 10px; width: 100%; height: auto;"
                     loading="lazy"/>
                <figcaption class="is-size-6" style="margin-top: 0.5rem;">
                  Diffusion Policy (DP) struggles with computation delays and fails to hit the ball in the ping-pong task.
                </figcaption>
              </figure>
            </div>
            <div class="column is-half has-text-centered">
              <figure>
                <img src="./static/images/pingpong_dadp.png"
                     style="border-radius: 10px; width: 100%; height: auto;"
                     loading="lazy"/>
                    <figcaption class="is-size-6" style="margin-top: 0.5rem;">
                      Our Delay-Aware Diffusion Policy (DA-DP) successfully handles highly dynamic, reactive tasks under inference delays.
                    </figcaption>
              </figure>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- TL;DR under hero -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-10">
        <h2 class="title is-4">TL;DR</h2>
        <div class="content">
          <ul>
            <li>item1</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Additional static items below abstract -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered">
      <div class="column is-7">
        <div class="summary-card">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              As a robot senses and selects actions, the world keeps changing. This inference delay creates a gap of tens to hundreds of milliseconds between the observed state and the state at execution. In this work, we take the natural generalization from zero delay to measured delay during training and inference. We introduce Delay-Aware Diffusion Policy (DA-DP), a framework for explicitly incorporating inference delays into policy learning. DA-DP corrects zero-delay trajectories to their delay-compensated counterparts, and augments the policy with delay conditioning. We empirically validate DA-DP on a variety of tasks, robots, and delays and find its success rate more robust to delay than delay-unaware methods. DA-DP is architecture agnostic and transfers beyond diffusion policies, offering a general pattern for delay-aware imitation learning. More broadly, DA-DP encourages evaluation protocols that report performance as a function of measured latency, not just task difficulty.
            </p>
          </div>
        </div>
      </div>
      <div class="column is-5">
        <video autoplay muted loop playsinline height="100%">
          <source src="./static/videos/pingpong_dadp.mp4" type="video/mp4">
        </video>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

  <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Pick up rolling ball results</h2>
        <div class="content has-text-justified">
          <p>
            We train StageACT on teleoperated demonstrations collected with a whole-body setup: a Unitree G1 with Dex-3 hands, where an Apple Vision Pro tracks the operator’s hands and retargets them to the robot via inverse kinematics. Locomotion is issued as simple base velocity commands while the operator controls arms and hands, which makes loco-manipulation teleop practical. The resulting dataset has 135 successful demos, gathered by two operators over two days in two offices (>8 hours). Each trajectory logs a 480×640 egocentric RGB image, a 29-D robot state (upper body, both hands, 
          </p>
          <div class="content has-text-centered" style="margin-top: 0.5rem;">
            <div style="max-width: 720px; margin: 0 auto;">
              <img src="./static/images/fig_method_teleop_v2.png" alt="Whole-body teleoperation overview" style="border-radius: 10px; width: 100%; height: auto;" loading="lazy"/>
              <p class="is-size-6 has-text-grey" style="margin-top: 0.5rem;">Overview of whole body teleoperation setup based on the G1 humanoid robot.</p>
            </div>
          </div>

          <p>
            To inject temporal context, we annotate five stages (search, approach, rotate, push, stop) offline, combining visual inspection with proprioceptive cues, where sharp torque spikes indicate contact transitions. During training and evaluation, these stage labels are one-hot vectors concatenated with the usual inputs so the policy can disambiguate look-alike observations and avoid mode collapse.
          </p>
          <div class="content has-text-centered" style="margin-top: 0.5rem;">
            <div style="max-width: 720px; margin: 0 auto;">
              <img src="./static/images/fig_method_phase_annotation_robot_v2.png" alt="Door opening phase annotation" style="border-radius: 10px; width: 100%; height: auto;" loading="lazy"/>
              <p class="is-size-6 has-text-grey" style="margin-top: 0.5rem;">Long-horizon task of door opening categorized into sub-stages.</p>
            </div>
          </div>
          <p>
            The learning recipe follows ACT with a small modification for stage input: we optimize a standard imitation reconstruction loss together with a KL regularizer, predict ~3-second action chunks, and temporally smooth them for stable execution. Hyperparameters and procedures mirror ACT, with changes only to accept the stage vector.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

</body>
</html>
